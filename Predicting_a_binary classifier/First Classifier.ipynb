{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdcec59",
   "metadata": {},
   "source": [
    "This Notebook's idea is to use correctly useful ML fuctions (like the other notebooks in this github). So All the result can be improved upon. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb977227",
   "metadata": {},
   "source": [
    "Some of the new topics that we are going to deal here are:\n",
    "+ RandomForestClassifier\n",
    "+ KNNImputer \n",
    "+ accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce96f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This Libraries were use in the other example because we needed to predict a numerical value\n",
    "# now we are predicting a category\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# New libraries that we haven't use yet!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# These functions are going to be use in the next notebook\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8582a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_02</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "PassengerId                                                         \n",
       "0001_01         Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "0002_01          Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "0003_01         Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "0003_02         Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "0004_01          Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "             RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n",
       "PassengerId                                                         \n",
       "0001_01              0.0        0.0           0.0     0.0     0.0   \n",
       "0002_01            109.0        9.0          25.0   549.0    44.0   \n",
       "0003_01             43.0     3576.0           0.0  6715.0    49.0   \n",
       "0003_02              0.0     1283.0         371.0  3329.0   193.0   \n",
       "0004_01            303.0       70.0         151.0   565.0     2.0   \n",
       "\n",
       "                          Name  \n",
       "PassengerId                     \n",
       "0001_01        Maham Ofracculy  \n",
       "0002_01           Juanna Vines  \n",
       "0003_01          Altark Susent  \n",
       "0003_02           Solam Susent  \n",
       "0004_01      Willy Santantines  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This data you can find here: https://www.kaggle.com/competitions/spaceship-titanic/data\n",
    "X_full = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "X_test_full = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "\n",
    "# Transported is the target, if there is no target eliminate row associated with it\n",
    "column_to_predict = \"Transported\"\n",
    "X_full.dropna(axis=0, subset=[column_to_predict], inplace=True)\n",
    "y = X_full[column_to_predict]\n",
    "X = X_full.copy()\n",
    "X.drop([column_to_predict], axis=1, inplace=True)\n",
    "X_test = X_test_full.copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f60e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n",
    "all_columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b96470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(X,delete_over=10,col_to_change_to_null=0.1):\n",
    "    \"\"\" \n",
    "    X: Dataframe that has to be cleaned\n",
    "    delete_over : columns that have more than delete_over categories will be deleted\n",
    "    col_to_change_to_null : If a column has more than col_to_change_to_null*100% values in null \n",
    "    it will create a new column that will be name column_name + _is_null and would be a boolean\n",
    "    marking 1 if it the value is null and 0 if not.\n",
    "    \n",
    "    \"\"\"\n",
    "    categorical_variables = [col for col in  X.columns if str(X[col].dtypes)=='object']\n",
    "    #numerical_variables = [col for col in X.columns if str(X[col].dtypes)!='object']\n",
    "    cardinalidad = {}\n",
    "    for col in categorical_variables:\n",
    "        cardinalidad[col] = len(list(X[col].unique()))\n",
    "    # For now we delete categories with more values than..\n",
    "    delete_over = delete_over\n",
    "    columns_to_delete = [col for col in categorical_variables if len(list(X[col].unique()))>delete_over ]\n",
    "    X.drop(columns=columns_to_delete,inplace = True, axis=1)\n",
    "    \n",
    "    # We are going to change columns with too many null.\n",
    "    # We are not gonna delete them, will give them the chance to be important.\n",
    "    # that means that having or not having the value is what is really important.\n",
    "    col_to_change_to_null = col_to_change_to_null\n",
    "    columnas_modificar_por_1 = [col for col in X.columns if X[col].isnull().sum()>int(X.shape[0] * col_to_change_to_null) ]\n",
    "\n",
    "    for col in columnas_modificar_por_1:\n",
    "        X[col +str('_is_null')] = 0\n",
    "        X.loc[(X[col].isnull()),col +str('_is_null')] = 1\n",
    "\n",
    "    new_columns_null = [str(f\"{col}_is_null\") for col in columnas_modificar_por_1 ]    \n",
    "    X.drop(columns=columnas_modificar_por_1, axis=1,inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea20acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaning_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e29b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_02</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            HomePlanet CryoSleep  Destination   Age    VIP  RoomService  \\\n",
       "PassengerId                                                               \n",
       "0001_01         Europa     False  TRAPPIST-1e  39.0  False          0.0   \n",
       "0002_01          Earth     False  TRAPPIST-1e  24.0  False        109.0   \n",
       "0003_01         Europa     False  TRAPPIST-1e  58.0   True         43.0   \n",
       "0003_02         Europa     False  TRAPPIST-1e  33.0  False          0.0   \n",
       "0004_01          Earth     False  TRAPPIST-1e  16.0  False        303.0   \n",
       "\n",
       "             FoodCourt  ShoppingMall     Spa  VRDeck  \n",
       "PassengerId                                           \n",
       "0001_01            0.0           0.0     0.0     0.0  \n",
       "0002_01            9.0          25.0   549.0    44.0  \n",
       "0003_01         3576.0           0.0  6715.0    49.0  \n",
       "0003_02         1283.0         371.0  3329.0   193.0  \n",
       "0004_01           70.0         151.0   565.0     2.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = X.columns\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bdf11f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cabin', 'Name'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns deleted given the criterion from the function cleaning_data\n",
    "deleted_columns = set(all_columns) - set(new_columns)\n",
    "deleted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4807469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_modeling_scoring(X,y,cv=3,n_jobs=-1,n_iter=15, scoring='accuracy'):\n",
    "    # separating the data in training/validation\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "    #                                                  random_state=0)        \n",
    "    \n",
    "    # We are gonna use a cross validation now\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    numerical_col = [col for col in X_train.columns if str(X_train[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X_train[col].isnull().any()==True]\n",
    "\n",
    "    categorical_col = [col for col in X_train.columns if str(X_train[col].dtypes)=='object' ]\n",
    "    categorical_col_imputed = [col for col in categorical_col if X_train[col].isnull().any()==True]\n",
    "\n",
    "    numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    categorical_transformer =  Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_col)],remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestClassifier(random_state=0,n_jobs=n_jobs)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    # pipe.fit(X_train,y_train)\n",
    "    \n",
    "    # scores = -1 * cross_val_score(pipe, X, y,cv=cv,scoring='accuracy')\n",
    "    distributions = dict(model__n_estimators=randint(low=10,high=500))\n",
    "    clf = RandomizedSearchCV(pipe, distributions, random_state=0, cv=cv,n_iter=n_iter,scoring=scoring)\n",
    "    search = clf.fit(X_train,y_train)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4199a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = transforming_modeling_scoring(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aebe906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d384cb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 97}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd640bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7793640629482805"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136f3a3",
   "metadata": {},
   "source": [
    "here we are creating a 2 version of the function above because we are going to try a new imputer! to see how it does. The new imputer is KNNImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8074627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_modeling_scoring_2(X,y,cv=3,n_jobs=-1,n_iter=15, scoring='accuracy'):\n",
    "    # separating the data in training/validation\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "    #                                                  random_state=0)        \n",
    "    \n",
    "    # We are gonna use a cross validation now\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    numerical_col = [col for col in X_train.columns if str(X_train[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X_train[col].isnull().any()==True]\n",
    "\n",
    "    categorical_col = [col for col in X_train.columns if str(X_train[col].dtypes)=='object' ]\n",
    "    categorical_col_imputed = [col for col in categorical_col if X_train[col].isnull().any()==True]\n",
    "    # n_neighbors = an integer. KNNImputer \n",
    "    numerical_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"imputer\", KNNImputer())\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    categorical_transformer =  Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_col)],remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestClassifier(random_state=0,n_jobs=n_jobs)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    # pipe.fit(X_train,y_train)\n",
    "    \n",
    "    # scores = -1 * cross_val_score(pipe, X, y,cv=cv,scoring='accuracy')\n",
    "    distributions = dict(model__n_estimators=randint(low=10,high=500))\n",
    "    \n",
    "    distributions = {\n",
    "    'preprocessor__numerical_transformer__imputer__n_neighbors':randint(low=1,high=7),\n",
    "    'model__max_depth':randint(low=2,high=20),\n",
    "    'model__n_estimators':randint(low=10,high=500),\n",
    "      }\n",
    "    clf = RandomizedSearchCV(pipe, distributions, random_state=0, cv=cv,n_iter=n_iter,scoring=scoring)\n",
    "    search = clf.fit(X_train,y_train)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b21bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = transforming_modeling_scoring_2(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc298db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 8,\n",
       " 'model__n_estimators': 49,\n",
       " 'preprocessor__numerical_transformer__imputer__n_neighbors': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be39a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951240818599855"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a14d50",
   "metadata": {},
   "source": [
    "Notemos todo lo que mejoró nuestro prónostico permitiendo a nuestro modelo escoger los mejores parametros en base a accuracy. Note también que cambiamos el simple imputer por uno más elaborado (KNNImputer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c67f4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72737d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
