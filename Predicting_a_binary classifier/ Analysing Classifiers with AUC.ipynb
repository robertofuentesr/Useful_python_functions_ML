{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31e426e",
   "metadata": {},
   "source": [
    "Remainder:\n",
    "\n",
    "In the last notebook we got the best RandomForestClassifier model with this parameters:\n",
    "{'model__max_depth': 8,\n",
    " 'model__n_estimators': 49,\n",
    " 'preprocessor__numerical_transformer__imputer__n_neighbors': 1}\n",
    " \n",
    "When I say the best I mean if we consider in the **scoring method just accuracy**, that with the previous model we got: 0.795 .. nearly 80% accuracy in their predictions.\n",
    "\n",
    "But when we are dealing with classifier we can use differents scorings. Not all error are equally important. when we incorrectly classified and operation we can do two types of mistakes, incorrecly saying is positive or incorrecly saying is negative. We say we **False positive** and **False negative** respectively.\n",
    "\n",
    "**False positive**: we predict were positive but were negative instead.\n",
    "**False negative**: we predict were negative but were positive instead.\n",
    "There a lot of materials in the internet, so we will not delve into it. But we are going to tune machine learning models giving this errors' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4731a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This Libraries were use in the other example because we needed to predict a numerical value\n",
    "# now we are predicting a category\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# New libraries that we haven't use yet!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# These functions are going to be use in the next notebook\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f85cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data you can find here: https://www.kaggle.com/competitions/spaceship-titanic/data\n",
    "X_full = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "\n",
    "# This is the real test, but we are going to use a test created by us to use easily ROC-AUC\n",
    "\n",
    "# X_test_full = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "\n",
    "# Transported is the target, if there is no target eliminate row associated with it\n",
    "column_to_predict = \"Transported\"\n",
    "X_full.dropna(axis=0, subset=[column_to_predict], inplace=True)\n",
    "y = X_full[column_to_predict]\n",
    "X = X_full.copy()\n",
    "X.drop([column_to_predict], axis=1, inplace=True)\n",
    "\n",
    "all_columns = X.columns\n",
    "\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                random_state=0)  \n",
    "#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832f1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(X,delete_over=10,col_to_change_to_null=0.1):\n",
    "    \"\"\" \n",
    "    X: Dataframe that has to be cleaned\n",
    "    delete_over : columns that have more than delete_over categories will be deleted\n",
    "    col_to_change_to_null : If a column has more than col_to_change_to_null*100% values in null \n",
    "    it will create a new column that will be name column_name + _is_null and would be a boolean\n",
    "    marking 1 if it the value is null and 0 if not.\n",
    "    \n",
    "    \"\"\"\n",
    "    categorical_variables = [col for col in  X.columns if str(X[col].dtypes)=='object']\n",
    "    #numerical_variables = [col for col in X.columns if str(X[col].dtypes)!='object']\n",
    "    cardinalidad = {}\n",
    "    for col in categorical_variables:\n",
    "        cardinalidad[col] = len(list(X[col].unique()))\n",
    "    # For now we delete categories with more values than..\n",
    "    delete_over = delete_over\n",
    "    columns_to_delete = [col for col in categorical_variables if len(list(X[col].unique()))>delete_over ]\n",
    "    X.drop(columns=columns_to_delete,inplace = True, axis=1)\n",
    "    \n",
    "    # We are going to change columns with too many null.\n",
    "    # We are not gonna delete them, will give them the chance to be important.\n",
    "    # that means that having or not having the value is what is really important.\n",
    "    col_to_change_to_null = col_to_change_to_null\n",
    "    columnas_modificar_por_1 = [col for col in X.columns if X[col].isnull().sum()>int(X.shape[0] * col_to_change_to_null) ]\n",
    "\n",
    "    for col in columnas_modificar_por_1:\n",
    "        X[col +str('_is_null')] = 0\n",
    "        X.loc[(X[col].isnull()),col +str('_is_null')] = 1\n",
    "\n",
    "    new_columns_null = [str(f\"{col}_is_null\") for col in columnas_modificar_por_1 ]    \n",
    "    X.drop(columns=columnas_modificar_por_1, axis=1,inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903764e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cabin', 'Name'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cleaning_data(X)\n",
    "new_columns = X.columns\n",
    "# columns deleted given the criterion from the function cleaning_data\n",
    "deleted_columns = set(all_columns) - set(new_columns)\n",
    "deleted_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae322576",
   "metadata": {},
   "source": [
    "We are going to compare two models, the first would be the best model we got in the previous notebook when we use scoring accuracy, and the second model when we use a scoring of AUC ( ‘roc_auc’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a1b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_model(X,y,X_test=False, y_test=False,\n",
    "             cv=3,n_jobs=-1,scoring='accuracy',\n",
    "             max_depth=8,n_estimators=49,n_neighbors=1 ):\n",
    "    # separating the data in training/validation\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "    #                                                  random_state=0)        \n",
    "    \n",
    "    # We are gonna use a cross validation now\n",
    "    \n",
    "    \"\"\"\n",
    "    previous model was: \n",
    "    {'model__max_depth': 8,\n",
    "     'model__n_estimators': 49,\n",
    "     'preprocessor__numerical_transformer__imputer__n_neighbors': 1}\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    numerical_col = [col for col in X_train.columns if str(X_train[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X_train[col].isnull().any()==True]\n",
    "\n",
    "    categorical_col = [col for col in X_train.columns if str(X_train[col].dtypes)=='object' ]\n",
    "    categorical_col_imputed = [col for col in categorical_col if X_train[col].isnull().any()==True]\n",
    "    # n_neighbors = an integer. KNNImputer \n",
    "    numerical_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"imputer\", KNNImputer(n_neighbors=n_neighbors))\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    categorical_transformer =  Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_col)],remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestClassifier(max_depth=max_depth,n_estimators=n_estimators ,random_state=0,n_jobs=n_jobs)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    model_fit = pipe.fit(X_train,y_train)\n",
    "    scores =  cross_val_score(pipe, X, y,cv=cv,scoring=scoring)\n",
    "    fpr, tpr, thresholds = [0],[0],[0]\n",
    "    try:\n",
    "        # X_test = False this will not run and it is ok\n",
    "        y_proba = pipe.predict_proba(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return model_fit,scores,fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd8360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit,first_model_accuracy,_, _, _ = fix_model(X,y,cv=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2b0971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7913431118780557"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model_accuracy.mean() # nearly the same score than before, now it is different, because it was trained in less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95808c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_fit,first_model_roc_auc\u001b[38;5;241m=\u001b[39m fix_model(X,y,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model_fit,first_model_roc_auc= fix_model(X,y,cv=3,n_jobs=-1,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_roc_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_modeling_scoring_2(X,y,cv=3,n_jobs=-1,n_iter=15, scoring='accuracy'):\n",
    "    # separating the data in training/validation\n",
    "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "    #                                                  random_state=0)        \n",
    "    \n",
    "    # We are gonna use a cross validation now\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    numerical_col = [col for col in X_train.columns if str(X_train[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X_train[col].isnull().any()==True]\n",
    "\n",
    "    categorical_col = [col for col in X_train.columns if str(X_train[col].dtypes)=='object' ]\n",
    "    categorical_col_imputed = [col for col in categorical_col if X_train[col].isnull().any()==True]\n",
    "    # n_neighbors = an integer. KNNImputer \n",
    "    numerical_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"imputer\", KNNImputer())\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    categorical_transformer =  Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_col)],remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestClassifier(random_state=0,n_jobs=n_jobs)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    # pipe.fit(X_train,y_train)\n",
    "    \n",
    "    # scores = -1 * cross_val_score(pipe, X, y,cv=cv,scoring='accuracy')\n",
    "    distributions = dict(model__n_estimators=randint(low=10,high=500))\n",
    "    \n",
    "    distributions = {\n",
    "    'preprocessor__numerical_transformer__imputer__n_neighbors':randint(low=1,high=7),\n",
    "    'model__max_depth':randint(low=2,high=20),\n",
    "    'model__n_estimators':randint(low=10,high=500),\n",
    "      }\n",
    "    clf = RandomizedSearchCV(pipe, distributions, random_state=0, cv=cv,n_iter=n_iter,scoring=scoring)\n",
    "    search = clf.fit(X_train,y_train)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca696e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aumentamos n_iter para tener otro modelo, ya que n_iter=15 nos da el mismo modelo y no podemos,\n",
    "# contrarestar uno con el otro con gráficos. (Al parecer con ambos scoring se llega al mismo modelo, puede checkearlo usted mismo!)\n",
    "search = transforming_modeling_scoring_2(X,y,scoring='roc_auc',n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd260371",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b15519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aaa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use the test data to test our two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dce4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cleaning_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_fit,first_model_auc,fpr, tpr, thresholds= fix_model(X,y,X_test,y_test, \n",
    "                                                            max_depth=8,n_estimators=49,\n",
    "                                                            n_neighbors=1,scoring='roc_auc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model_fit,second_model_auc,fpr_2, tpr_2, thresholds_2= fix_model(X,y,X_test, y_test,\n",
    "                                                                     max_depth=10,n_estimators=344,\n",
    "                                                                     n_neighbors=5,scoring='roc_auc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b66c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ploting ROC\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr,\n",
    "                    mode='lines+markers',\n",
    "                    name=f'ROC-AUC for the 1st model: {round(first_model_auc.mean(),4)}'))\n",
    "fig.add_trace(go.Scatter(x=fpr_2, y=tpr_2,\n",
    "                    mode='lines+markers',\n",
    "                    name=f'ROC-AUC for the 2nd model: {round(second_model_auc.mean(),4)}'))\n",
    "fig.update_layout(\n",
    "    title=\"ROC Curve\",\n",
    "    xaxis_title=\"FPR\",\n",
    "    yaxis_title=\"FPR\",    \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444e9d4",
   "metadata": {},
   "source": [
    "This is the famous ROC Curve as you can see the AUC (area under the ROC curve) goes from 0 to 1. But realistic goes to 0.5 to 1, because we can always construct a base model that it is line (you can look it up on the internet). So keep it mind that the closest to 1 the AUC value is, the better is the model. Values too near 0.5 are very bad, because they are predicting near to a complete randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57221437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
