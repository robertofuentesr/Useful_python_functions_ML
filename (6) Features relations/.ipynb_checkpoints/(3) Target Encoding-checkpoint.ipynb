{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ca5cf5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a series that I am very excited about. We are going to explore some unsupervised models, the main idea is to understand the X-space or the space of the feautures.\n",
    "\n",
    "All the other things we saw so far explore how feautures helps us make certain kind of predictions. And then we look deeper at the model itself and try to explain how those feauture impact the model (shap and permutation analysis).\n",
    "\n",
    "But we haven't stopped to analysis with greater care how all the feautures that make those predictions move together. That what we are going to explore here. Graph theory was the only exception, because with graph theory we understand the underlying pattern of connections.\n",
    "\n",
    "We already saw PCA and SVD. Now we are going to do something more subtle to the categorical variables, hopefully increasing their predicting power.\n",
    "\n",
    "In this notebook we are going to explore Target Encoding.\n",
    "you can read more here: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9857f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "# new library, we haven't used this one before in this repo\n",
    "from sklearn.preprocessing import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f50df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "# This data you can find here: https://www.kaggle.com/c/home-data-for-ml-course/data\n",
    "\n",
    "X_full = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "# SalePrice is the target, if there is no target eliminate row associated with it\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X = X_full.copy()\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a63f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_score(X,\n",
    "                         y,\n",
    "                         n_estimators=369,\n",
    "                         cv=5,\n",
    "                         scoring='neg_mean_absolute_error',\n",
    "                         target_encoding='yes'):\n",
    "\n",
    "    \n",
    "    numerical_col = [col for col in X.columns if str(X[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X[col].isnull().any()==True]\n",
    "\n",
    "    categorical_col = [col for col in X.columns if str(X[col].dtypes)=='object' ]\n",
    "    categorical_col_imputed = [col for col in categorical_col if X[col].isnull().any()==True]\n",
    "\n",
    "    numerical_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"imputer\", KNNImputer(n_neighbors=3))\n",
    "      ]\n",
    "        )\n",
    "\n",
    "    if target_encoding ==\"no\":\n",
    "        categorical_transformer =  Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "    elif target_encoding ==\"yes\":\n",
    "        categorical_transformer =  Pipeline(steps=[\n",
    "            ('encoder', TargetEncoder(smooth=\"auto\",target_type='continuous'))\n",
    "        ])\n",
    "        \n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_col)],remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators,random_state=0,n_jobs=-1)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    \n",
    "    scores = -1 * cross_val_score(pipe, X, y,cv=cv,scoring=scoring)\n",
    "\n",
    "    return scores,pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ccfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,pipe = model_pipeline_score(X,y,target_encoding='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac07ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17332.533775104872"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fe2d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d9f9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,pipe  = model_pipeline_score(X,y,target_encoding='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa48f8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17572.00848461224"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a593af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a609c4",
   "metadata": {},
   "source": [
    "This was interesting! we use target encoding in all columns and it seems it work better than one-hot encoding. We are going to play a little with the max cardinality to lower the mae even more!. So what we are going to do next is to use target enconding in categorical columns who has a high cardinality and not in others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e6f881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_score(X,\n",
    "                         y,\n",
    "                         n_estimators=369,\n",
    "                         cv=5,\n",
    "                         scoring='neg_mean_absolute_error',\n",
    "                         cardinaity_target=13):\n",
    "\n",
    "    \n",
    "    numerical_col = [col for col in X.columns if str(X[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X[col].isnull().any()==True]\n",
    "    enc_target = [col for col in list(X.columns) if str(X[col].dtypes)=='object' and len(X[col].unique())>cardinaity_target ]\n",
    "   \n",
    "    all_categories = [col for col in list(X.columns) if str(X[col].dtypes)=='object']\n",
    "    col_encoding = [col for col in all_categories if col not in enc_target ]\n",
    "    \n",
    "   \n",
    "    numerical_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), \n",
    "           (\"imputer\", KNNImputer(n_neighbors=3))\n",
    "          ])\n",
    "\n",
    "\n",
    "\n",
    "    target_transformer =  Pipeline(steps=[\n",
    "        ('encoder', TargetEncoder(smooth=\"auto\",target_type='continuous'))\n",
    "    ])\n",
    "        \n",
    "    categorical_transformer =  Pipeline(\n",
    "        steps=[('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])    \n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "         (\"target_transformer\", target_transformer, enc_target),\n",
    "        (\"categorical_transformer\", categorical_transformer, col_encoding)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators,random_state=0,n_jobs=-1)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    \n",
    "    scores = -1 * cross_val_score(pipe, X, y,cv=cv,scoring=scoring)\n",
    "\n",
    "    return scores,pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964daa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in range(5,20,3):\n",
    "    best_number = 100\n",
    "    min_score = 17572\n",
    "    scores,pipe = model_pipeline_score(X,y,cardinaity_target=number)\n",
    "    if scores.mean() < min_score:\n",
    "        min_score = scores.mean() \n",
    "        best_number = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a962336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17245.58469948398"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f08fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873603d0",
   "metadata": {},
   "source": [
    "We just obtain the best MAE we have got so far! \n",
    "Notice the best MAE it just happened to be the one that uses TargetEncoder with columns with high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f6391cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neighborhood']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_col = [col for col in X.columns if str(X[col].dtypes)!='object' ]\n",
    "numerical_col_imputed = [col for col in numerical_col if X[col].isnull().any()==True]\n",
    "enc_target = [col for col in list(X.columns) if str(X[col].dtypes)=='object' and len(X[col].unique())>17 ]\n",
    "\n",
    "all_categories = [col for col in list(X.columns) if str(X[col].dtypes)=='object']\n",
    "col_encoding = [col for col in all_categories if col not in enc_target ]\n",
    "enc_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f843648",
   "metadata": {},
   "source": [
    "Notice the best transform uses only one column as TargetEncoder who has more than 17 types of neighborhoods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
