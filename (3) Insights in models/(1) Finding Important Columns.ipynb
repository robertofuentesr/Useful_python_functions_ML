{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a1f4be",
   "metadata": {},
   "source": [
    "I already created some machine learning models in this repo but I haven't say anything about what columns are important. That is a very important aspects that we need to address, when we understand what column are important we can:\n",
    "+ trust the result of the model\n",
    "+ take inform decision\n",
    "+ in case we need to collect new data (Generally expensive), we know what variables play a key role and thus we need to collect.\n",
    "\n",
    "So this is the purpose of this notebook and the next in this folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f678204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "# new libraries not use yet\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb6f0e",
   "metadata": {},
   "source": [
    "### How we are going to train this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4261d31",
   "metadata": {},
   "source": [
    "Previously we got the best model with n_estimators=369 when we use the **whole training data using cross validation**.\n",
    "We could improve the model even further but instead of doing that our focus is in getting the most important variables and their impact.\n",
    "\n",
    "We are going to keep this hyperparameter but we are going to train a model with less data, because we are going to separate in the training set in training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936418fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "# This data you can find here: https://www.kaggle.com/c/home-data-for-ml-course/data\n",
    "\n",
    "X_full = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "# SalePrice is the target, if there is no target eliminate row associated with it\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X = X_full.copy()\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd5033",
   "metadata": {},
   "source": [
    "The next cell just uses the same function that we saw in the \"(1) Predicting_a_numerical_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d745f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(X,delete_over=10,col_to_change_to_null=0.1):\n",
    "    \n",
    "    categorical_variables = [col for col in  X.columns if str(X[col].dtypes)=='object']\n",
    "    #numerical_variables = [col for col in X.columns if str(X[col].dtypes)!='object']\n",
    "    cardinalidad = {}\n",
    "    for col in categorical_variables:\n",
    "        cardinalidad[col] = len(list(X[col].unique()))\n",
    "    # For now we delete categories with more values than..\n",
    "    delete_over = delete_over\n",
    "    columns_to_delete = [col for col in categorical_variables if len(list(X[col].unique()))>delete_over ]\n",
    "    X.drop(columns=columns_to_delete,inplace = True, axis=1)\n",
    "    \n",
    "    # We are going to change columns with too many null.\n",
    "    # We are not gonna delete them, will give them the chance to be important.\n",
    "    # that means that having or not having the value is what is really important.\n",
    "    col_to_change_to_null = col_to_change_to_null\n",
    "    columnas_modificar_por_1 = [col for col in X.columns if X[col].isnull().sum()>int(X.shape[0] * col_to_change_to_null) ]\n",
    "\n",
    "    for col in columnas_modificar_por_1:\n",
    "        X[col +str('_is_null')] = 0\n",
    "        X.loc[(X[col].isnull()),col +str('_is_null')] = 1\n",
    "\n",
    "    new_columns_null = [str(f\"{col}_is_null\") for col in columnas_modificar_por_1 ]    \n",
    "    X.drop(columns=columnas_modificar_por_1, axis=1,inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09f50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaning_data(X)\n",
    "X, X_val, y, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3011c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_modeling_scoring(X,y, n_estimators=369,n_jobs=-1):\n",
    "      \n",
    "    numerical_col = [col for col in X.columns if str(X[col].dtypes)!='object' ]\n",
    "    numerical_col_imputed = [col for col in numerical_col if X[col].isnull().any()==True]\n",
    "\n",
    "    categorical_col = [col for col in X.columns if str(X[col].dtypes)=='object' ]\n",
    "    categorical_col_imputed = [col for col in categorical_col if X[col].isnull().any()==True]\n",
    "\n",
    "    numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    categorical_transformer =  Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=pd.NA, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=\n",
    "        [(\"numerical_transformer\", numerical_transformer, numerical_col_imputed),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_col)],remainder='passthrough')\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators,random_state=0,n_jobs=n_jobs)\n",
    "\n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)\n",
    "                         ])\n",
    "\n",
    "    model = pipe.fit(X,y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afd0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transforming_modeling_scoring(X,y, n_estimators=369)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6fcdc",
   "metadata": {},
   "source": [
    "## Finding the most important columns and their impact on the scoring (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3a92b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = permutation_importance(model,X_val, y_val, random_state=0,scoring='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efe3f995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual    22250.107131\n",
       "GrLivArea       9916.359132\n",
       "TotalBsmtSF     2277.740695\n",
       "BsmtFinSF1      1140.381615\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_importances = pd.Series(perm.importances_mean, index=X_val.columns)\n",
    "# the value with negative values are unimportant, because that means\n",
    "# that changing the values of these columns actually improve the model\n",
    "model_importances = model_importances[model_importances>0]\n",
    "model_importances.sort_values(ascending=False)[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db59d4c2",
   "metadata": {},
   "source": [
    "These are the most important variables:\n",
    "+ OverallQual: Overall material and finish quality         \n",
    "+ GrLivArea: Above grade (ground) living area square feet             \n",
    "+ TotalBsmtSF: Total square feet of basement area            \n",
    "+ BsmtFinSF1: Type 1 finished square feet             \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7db7da6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180808.89897260274"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember that the\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2891c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Notice the amount of information or importance that the \n",
      "most impacful variable has it is: 12.31%. So saying it correctly\n",
      "that number indicates how much we worsen the MAE scoring if we shuffle \n",
      "at random that column, that is a big impact!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# so the amount of information that OverallQual has is around\n",
    "information = (model_importances['OverallQual']/y.mean())*100\n",
    "print(f\"\"\" Notice the amount of information or importance that the \n",
    "most impacful variable has it is: {round(information,2)}%. So saying it correctly\n",
    "that number indicates how much we worsen the MAE scoring if we shuffle \n",
    "at random that column, that is a big impact!!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
